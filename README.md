# The Mosaic memory of Large Language Models

We here elaborate on the code used to generate the results discussed in our manuscript. 

## (1) Setting up the environment

- `conda create --name canary python=3.9`
- `pip install -r requirements.txt` (this folder)

Some models used in this reposority require you to be authenticated on Hugging Face (and have accepted certain model licenses). If you wish to use these models, you will need to log in on Hugging Face, using `huggingface-cli login` and providing your token. 

If you wish to report model training results to Weigths and Biases (as by default in this repository), you will also need to provide a wandb-tokenn when prompted.

## (2) Main functionality

**2.1 Generating reference canaries.**

Reference canaries are generated by sampling synthetic data from Llama-2-7B with a certain temperature. 
The code used to do so can be found in `./src/generate_canaries.py`, alongside the script `./scripts/generate_canaries.sh`.

Note that we use the same script ot generate 'member' and 'non-member' canaries, using random seed of 42 and 420 respectively. 
The temperature used to sample from the model's predicted probability can be set with the variable `temp`, and is set to 1 for our main results.  

The resulting canaries are saved in a pickle file in the desired directory.

**2.2 Generating fuzzy duplicates**

Fuzzy duplicates can be created using `./src/generate_variations.py`, like in the script `./script/generate_near_duplicates.sh`. 

The main parameters can passed as arguments to the script:
- 'candidate-gen-strategy': determines the strategy used to create the fuzzy duplicates. All results in the paper use strategy `mlm` (replacing tokens by one sampled from the top-k predictions from a masked language model) or `mlm_random` when k is set to the vocabulary size. 
- 'topk' determines the pool from which the tokens are sampled, where lower values correspond to more semantically meaningful replacements. Throught most experiments we set topk to 10.
- when 'no-replace-same-indices' is passed as arguments, the tokens are replaced at different indicies in the reference canary for each of the 'num-variations'
- 'num-injection-points' determines the number of tokens to be replaced. 

**2.3 Getting the books for finetuning.**

We randomly sample 100 books from the dataset containing books from Project Gutenberg not part of PG-19, to be downloaded [here](https://huggingface.co/datasets/imperial-cpg/project-gutenberg-extended).

For reproducibility, we also provide the exact books we used in this work in `./notebooks/recover_books.ipynb`.

**2.4 Injecting canaries into the dataset**

We inject the reference canaries and their fuzzy duplicates in all the books. We provide the code to do so in `./notebooks/NearDuplicatesInjection.ipynb`

**2.5 Model training**

Now we have the reference canaries injected in the dataset, we can finetune the target model. 
For each set of fuzzy duplicates, we will repeat the finetuning to get to a different target model to be used for membership inference.

The main code to finetune the target model is provided in `./src/fine_tune_model.py`. 
We provide scripts to finetune all models for exact duplicates and fuzzy duplicates sequentually in `./scripts/finetune_gptneo_exact_dupls.sh` and `./scripts/finetune_gptneo_near_dupls.sh`.

The script takes as arguments the training hyperparameters, the training data (i.e. the books with injected duplicates) and the path to member and non-member reference canaries. 
It uses the latter to monitor MIA AUC (using the Loss attack) during training. 

By default, the script report the training to Weights and Biases, which will require a login if you'd like to use this as well.

Other setups considered in the paper (different base model, learning rate, etc) can be easily achieved by updating the parameters. 

At the end of training, the final model is saved to the desired directory, which we will then use for final membership inference results. 

**2.6 Membership inference**

Now we have the finetuned models, we want to evaluate the MIA. 
We run this for each target model individually and sequentially, with example code provided in `./notebooks/membership_inference_example.ipynb`. 

The results are then saved as a pickle file, to be used for plotting. 

**2.7 Plotting results**

Example plotting results (for the main figures), including the computation of the custom metric rho, can be found in `./notebooks/metric_figure.ipynb`.

## (3) Secondary experiments

In our paper, we also provide a range of secondary experiments and results. We elaborate on the code used for that below. 

**3.1 Insertion of random tokens**

The code to create the dataset, and analyze the results is in `./notebooks/insertion.ipynb` and `./notebooks/insertion_results.ipynb`, respectively, while the associated script is `./scripts/finetune_gptneo_insertions.sh`.

**3.2 Shuffling of tokens**

The code to create the dataset, and analyze the results is in `kendall_tau.ipynb` and `kendall_tau_results.ipynb`, respectively, while the associated script is `./scripts/finetune_gptneo_shuffle.sh`.

**3.3 Paraphrasing**

**3.4 Ablations**

## (4) Finding fuzzy duplicates in a real-world dataset

