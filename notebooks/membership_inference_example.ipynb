{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb59a93-8f34-4f49-9dba-89f0cc79770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"PATH_TO_SRC_DIR\") # Replace with the actual path to your source directory\n",
    "\n",
    "# Enable hot autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacaf596-0603-4531-af0a-59e6192c84de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthieu/miniconda3/envs/canary/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch\n",
    "from typing import Sequence\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, LlamaForCausalLM\n",
    "from utils import compute_perplexity, ratio_auc, min_k_prob\n",
    "import zlib\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634db28d",
   "metadata": {},
   "source": [
    "## Compuring membership inference results\n",
    "\n",
    "In this notebook, we provide the code to run MIAs against the saved target model, finetuned on a dataset containing (fuzzy) duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a28dad-15c3-4c18-b840-5c87ef9b4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "OG_NON_MEMBER_PATH = \"SOME_DATA_DIR/non_members.pickle\"\n",
    "OG_CANARY_PATH = \"SOME_DATA_DIR/members.pickle\"\n",
    "\n",
    "LLAMA_TOKENIZER_PATH = \"SOME_DATA_DIR/Llama-2-7b-hf/\"\n",
    "LLAMA_MODEL_PATH = \"SOME_DATA_DIR/Llama-2-7b-hf/\"\n",
    "\n",
    "TARGET_MODEL = \"EleutherAI/gpt-neo-1.3B\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f13aea-f7f0-4f28-a320-24823699f518",
   "metadata": {},
   "source": [
    "## Let's apply MIAs for all fuzzy duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4841e5-b9dc-4587-95ef-1b3ddce13341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "llama_device = \"cuda:0\"\n",
    "llama_tokenizer = LlamaTokenizer.from_pretrained(LLAMA_TOKENIZER_PATH, torch_dtype=torch.float16)\n",
    "llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "llama_model = LlamaForCausalLM.from_pretrained(LLAMA_MODEL_PATH).to(llama_device)\n",
    "\n",
    "target_tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL)\n",
    "target_tokenizer.pad_token = target_tokenizer.eos_token\n",
    "target_device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b562cb14-46cd-4458-b204-40245dd13643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the canary text\n",
    "with open(OG_CANARY_PATH, 'rb') as f:\n",
    "    og_canaries = pickle.load(f)\n",
    "    \n",
    "og_canary_texts = [target_tokenizer.decode(og_canary) for og_canary in og_canaries]\n",
    "og_canary_texts_lower = [x.lower() for x in og_canary_texts]\n",
    "\n",
    "# and the non member text\n",
    "with open(OG_NON_MEMBER_PATH, 'rb') as f:\n",
    "    non_members = pickle.load(f)\n",
    "\n",
    "non_member_texts = [target_tokenizer.decode(non_member) for non_member in non_members]\n",
    "non_member_texts_lower = [x.lower() for x in non_member_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2532c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(members: Sequence[float], non_members: Sequence[float]):\n",
    "    y = []\n",
    "    y_true = []\n",
    "\n",
    "    y.extend(members)\n",
    "    y.extend(non_members)\n",
    "\n",
    "    y_true.extend([0] * len(members))\n",
    "    y_true.extend([1] * len(non_members))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y)\n",
    "\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd334b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_at_fpr(members, non_members, target_fpr):\n",
    "    fpr, tpr = roc_auc(members, non_members)\n",
    "\n",
    "    index = np.abs(fpr - target_fpr).argmin()\n",
    "    return tpr[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38261151-752f-4c25-b929-b73336d9ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_with_bootstrapping(ratio_members, ratio_non_members, k=25):\n",
    "    all_aucs = list()\n",
    "    for _ in range(k):\n",
    "        subset_members = np.random.choice(ratio_members, len(ratio_members))\n",
    "        subset_non_members = np.random.choice(ratio_non_members, len(ratio_non_members))\n",
    "        auc = ratio_auc(members=subset_members, non_members=subset_non_members)\n",
    "        all_aucs.append(auc)\n",
    "    return np.array(all_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0828868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppl_from_text(texts, model, tokenizer, device):\n",
    "    tokens = tokenizer.batch_encode_plus(texts, return_tensors=\"pt\", padding=\"longest\").to(device)\n",
    "    ppl = compute_perplexity(\n",
    "        model,\n",
    "        tokens.input_ids[:, 1:],\n",
    "        tokens.attention_mask[:, 1:],\n",
    "        ignore_prefix=None\n",
    "    )\n",
    "\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5742ab-a896-4788-a61e-7ee6af967e77",
   "metadata": {},
   "source": [
    "# First let's do it for exact duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed5ed1-9fd2-421b-817b-b33339e02a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrep_aucs = defaultdict(dict)\n",
    "\n",
    "MODEL_CHECKPOINT_PATH = \"SOME_DATA_DIR/model_checkpoints/EleutherAI_gpt-neo-1.3B_checkpoints/EleutherAI_gpt-neo-1.3B_gptneo1B_exact_duplicates_nrepXX_lr2e5\"\n",
    "\n",
    "for nrep in (1, 2, 3, 4, 5, 6, 7, 8, 9, 10):\n",
    "\n",
    "    print(\"nrep = \", nrep)\n",
    "\n",
    "    score_members = {}\n",
    "    score_non_members = {}\n",
    "\n",
    "    target_path = MODEL_CHECKPOINT_PATH.replace(\"XX\", str(nrep))\n",
    "    \n",
    "    target_model = AutoModelForCausalLM.from_pretrained(target_path).to(target_device)\n",
    "\n",
    "    # first: non members\n",
    "    print(\"Running on non members...\")\n",
    "    non_member_target_ppl = ppl_from_text(non_member_texts, target_model, target_tokenizer, target_device)\n",
    "    non_member_llama_ppl = ppl_from_text(non_member_texts, llama_model, llama_tokenizer, llama_device)\n",
    "    non_member_lower_target_ppl = ppl_from_text(non_member_texts_lower, target_model, target_tokenizer, target_device)\n",
    "\n",
    "    target_tokens_non_members = target_tokenizer.batch_encode_plus(non_member_texts, return_tensors=\"pt\", padding=\"longest\").to(target_device)\n",
    "    non_member_zlib_entropy = [len(zlib.compress(x.encode()))/len(x) for x in non_member_texts]\n",
    "    \n",
    "    score_non_members[\"ratio\"] = non_member_target_ppl / non_member_llama_ppl\n",
    "    score_non_members[\"loss\"] = non_member_target_ppl\n",
    "    score_non_members[\"lowercase\"] = non_member_target_ppl / non_member_lower_target_ppl\n",
    "    score_non_members[\"minkprob\"] = -min_k_prob(target_model, target_tokens_non_members.input_ids, target_tokens_non_members.attention_mask)\n",
    "    score_non_members[\"zlib\"] = np.log(non_member_target_ppl) / non_member_zlib_entropy\n",
    "\n",
    "    # now: non members\n",
    "    print(\"Running on canaries...\")\n",
    "    og_canary_target_ppl = ppl_from_text(og_canary_texts, target_model, target_tokenizer, target_device)\n",
    "    og_canary_llama_ppl = ppl_from_text(og_canary_texts, llama_model, llama_tokenizer, llama_device)\n",
    "    og_canary_lower_target_ppl = ppl_from_text(og_canary_texts_lower, target_model, target_tokenizer, target_device)\n",
    "\n",
    "    target_tokens_og_canary = target_tokenizer.batch_encode_plus(og_canary_texts, return_tensors=\"pt\", padding=\"longest\").to(target_device)\n",
    "    og_canary_zlib_entropy = [len(zlib.compress(x.encode()))/len(x) for x in og_canary_texts]\n",
    "\n",
    "    score_members[\"ratio\"] = og_canary_target_ppl / og_canary_llama_ppl\n",
    "    score_members[\"loss\"] = og_canary_target_ppl\n",
    "    score_members[\"lowercase\"] = og_canary_target_ppl / og_canary_lower_target_ppl\n",
    "    score_members[\"minkprob\"] = -min_k_prob(target_model, target_tokens_og_canary.input_ids, target_tokens_og_canary.attention_mask)\n",
    "    score_members[\"zlib\"] = np.log(og_canary_target_ppl) / og_canary_zlib_entropy\n",
    "\n",
    "    for mia in score_members:\n",
    "        aucs = get_auc_with_bootstrapping(ratio_members=score_members[mia], ratio_non_members=score_non_members[mia])\n",
    "        tpr_at = tpr_at_fpr(score_members[mia], score_non_members[mia], target_fpr=0.1)\n",
    "        print(f\"nrep={nrep}, MIA={mia}, AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f}, TPR @ 0.1 FPR = {tpr_at:.2f}\")\n",
    "        nrep_aucs[nrep][mia] = aucs\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95812d3b-4f09-4825-bfbf-8baae29325d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "with open(\"SOME_DATA_DIR/nrep_aucs_gptneo1B_exactduplicates_lr2e5.pickle\", \"wb\") as f:\n",
    "    pickle.dump(nrep_aucs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381df0d",
   "metadata": {},
   "source": [
    "## Now also do the fuzzy duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c6eea-4e60-40c4-8a79-715fd0623056",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_aucs = defaultdict(dict)\n",
    "\n",
    "MODEL_CHECKPOINT_PATH = \"SOME_DATA_DIR/model_checkpoints/EleutherAI_gpt-neo-1.3B_checkpoints/EleutherAI_gpt-neo-1.3B_gptneo1B_near_duplicates_diff_indices_topk10_RXX_lr2e5\"\n",
    "\n",
    "for R in (1, 5, 10, 15, 20, 25, 50, 75):\n",
    "\n",
    "    print(\"R = \", R)\n",
    "\n",
    "    score_members = {}\n",
    "    score_non_members = {}\n",
    "\n",
    "    target_path = MODEL_CHECKPOINT_PATH.replace(\"XX\", str(R))\n",
    "    \n",
    "    target_model = AutoModelForCausalLM.from_pretrained(target_path).to(target_device)\n",
    "\n",
    "    # first: non members\n",
    "    print(\"Running on non members...\")\n",
    "    non_member_target_ppl = ppl_from_text(non_member_texts, target_model, target_tokenizer, target_device)\n",
    "    non_member_llama_ppl = ppl_from_text(non_member_texts, llama_model, llama_tokenizer, llama_device)\n",
    "    non_member_lower_target_ppl = ppl_from_text(non_member_texts_lower, target_model, target_tokenizer, target_device)\n",
    "\n",
    "    target_tokens_non_members = target_tokenizer.batch_encode_plus(non_member_texts, return_tensors=\"pt\", padding=\"longest\").to(target_device)\n",
    "    non_member_zlib_entropy = [len(zlib.compress(x.encode()))/len(x) for x in non_member_texts]\n",
    "    \n",
    "    score_non_members[\"ratio\"] = non_member_target_ppl / non_member_llama_ppl\n",
    "    score_non_members[\"loss\"] = non_member_target_ppl\n",
    "    score_non_members[\"lowercase\"] = non_member_target_ppl / non_member_lower_target_ppl\n",
    "    score_non_members[\"minkprob\"] = -min_k_prob(target_model, target_tokens_non_members.input_ids, target_tokens_non_members.attention_mask)\n",
    "    score_non_members[\"zlib\"] = np.log(non_member_target_ppl) / non_member_zlib_entropy\n",
    "\n",
    "    # now: non members\n",
    "    print(\"Running on canaries...\")\n",
    "    og_canary_target_ppl = ppl_from_text(og_canary_texts, target_model, target_tokenizer, target_device)\n",
    "    og_canary_llama_ppl = ppl_from_text(og_canary_texts, llama_model, llama_tokenizer, llama_device)\n",
    "    og_canary_lower_target_ppl = ppl_from_text(og_canary_texts_lower, target_model, target_tokenizer, target_device)\n",
    "\n",
    "    target_tokens_og_canary = target_tokenizer.batch_encode_plus(og_canary_texts, return_tensors=\"pt\", padding=\"longest\").to(target_device)\n",
    "    og_canary_zlib_entropy = [len(zlib.compress(x.encode()))/len(x) for x in og_canary_texts]\n",
    "\n",
    "    score_members[\"ratio\"] = og_canary_target_ppl / og_canary_llama_ppl\n",
    "    score_members[\"loss\"] = og_canary_target_ppl\n",
    "    score_members[\"lowercase\"] = og_canary_target_ppl / og_canary_lower_target_ppl\n",
    "    score_members[\"minkprob\"] = -min_k_prob(target_model, target_tokens_og_canary.input_ids, target_tokens_og_canary.attention_mask)\n",
    "    score_members[\"zlib\"] = np.log(og_canary_target_ppl) / og_canary_zlib_entropy\n",
    "\n",
    "    for mia in score_members:\n",
    "        aucs = get_auc_with_bootstrapping(ratio_members=score_members[mia], ratio_non_members=score_non_members[mia])\n",
    "        tpr_at = tpr_at_fpr(score_members[mia], score_non_members[mia], target_fpr=0.1)\n",
    "        print(f\"R={R}, MIA={mia}, AUC = {np.mean(aucs):.2f} ± {np.std(aucs):.2f}, TPR @ 0.1 FPR = {tpr_at:.2f}\")\n",
    "        R_aucs[R][mia] = aucs\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SOME_DATA_DIR/R_aucs_gptneo1B_nearduplicates_diffindices_topk10_RXX_lr2e5.pickle\", \"wb\") as f:\n",
    "   pickle.dump(R_aucs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "canary",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
